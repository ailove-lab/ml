section
  h2 Основы

section
  h3 Нейронная сеть
  img(src='img/nn_black_box.png')
  ul
    li Нейронная сеть это некий "черный ящик", мат-модель, имеющая вход и выход
    li Внутренне состоянии модели описывается параметрами $W$
    li На вход модели подаются данные $X$
    li На выходе получаем ответ $Y$

// section.
//   Задача обучения нейронной сети, заключается в поиске таких значений параметров модели $W$,
//   при котороых результат $Y$, будет иметь минимальную ошибку.
    
// section(data-markdown): textarea(data-template).
//   ### Сокращения
//   - ML - Machine Learning / машинное обучение
//   - NN - Artificial Neural Network / искуственные нейронные сети
//   - DL - Deep Learning / обучение глубоких нейронных сетей

  
section(data-markdown): textarea(data-template).
  ### Основные термины
  - [neuron]()              - нейрон (искуственный)
  - [activation function]() - функция активации
  - [error (loss)]()        - ошибка / функция потерь
  - [gradientdescent]()     - градиентный спуск
  - [backpropagation]()     - обратное распространение
  - [overfit]()             - переобучениe


section(data-markdown): textarea(data-template).
  ### Стандартные обозначения
  - [$X$]()      - входные данные подаваемый в модель
  - [$Y$]()      - ожидаемый результат
  - [$\hat Y$]() - полученный результат
  - [$E$]()      - ошибка предсказания
  - [$W$]()      - параметры модели

  
section
  h3 Совсем Немного математики
  img.plain.small(src="img/pushen_aaa.png")

    
section
  h3 линейнoe уравнение
  p.
    $$
    \begin{split}
    y & = w_0 + w_1 x_1 \\
    y & = w_0 + w_1 x_1 + w_2 x_2  \\
      & \cdots \\
    y & = w_0 + w_1 х_1 + w_2 х_2 + \cdots + w_n x_n \\
    \end{split}
    $$


section
  h3 вектор
  p $$ \vec{w}=[w_0,w_1,\cdots, w_n] $$

section
  h3 матрица
  p.
    $$ W_{n \times m} =
    \begin{bmatrix}
      w_{0,0} & w_{0,1} & \cdots & w_{0,m} \\
      w_{1,0} & w_{1,1} & \cdots & w_{1,m} \\
      \cdots  & \cdots  & \cdots & \cdots  \\
      w_{n,0} & w_{n,1} & \cdots & w_{n,m}
    \end{bmatrix}$$
  small Матрицы обычно обозначаются заглавными буквами $X$, a их элементы строчными $x_{i,j}$

section
  h3 матрицы можно умножать
  p $A \cdot B = C$
  small: ul
    li ширина матрицы $A$ должна быть равна высоте матрицы $B$
    li результатом умножения будет новая матрица

section
  h3 Геометрический смысл
  img(src='img/dot_product.png')

section
  h3 Математический смысл
  p.
    $$
      W_{1 \times n} = [w_0, w_1, \cdots, w_n] \\
      X_{1 \times n} = [x_0, x_1, \cdots, x_n] \\
      W \cdot X^T = [w_0 x_0 + w_1 x_1 + \cdots + w_n x_n]_{1 \times 1}
    $$
      
section
  h2 ВЫДЫХАЕМ
  h6 этого вполне достаточно чтобы разобраться с нейронными сетями
  img.plain.small(src="img/pushen_godfather.png")
// section
//   h4 функция
//   p $f$ - математическое действие над аргументом
    
//
  section(data-markdown): textarea(data-template).
    ### Общепринятые сокращения

    - ML - Machine Learning / машинное обучение
    - NN, ANN - Artificial Neural Network / искуственные нейронные сети
    - DL - Deep Learning / обучение глубоких нейронных сетей
    - CNN - Convolution Neural Net / сверточные нейронные сети
    - RNN - Recurrent Neural Net / рекурентные нейронные сети
    - GAN - Generativ Adversarial Net / генеративно конкурентные сети
    - TF - TensorFlow
// 
  section(data-markdown): textarea(data-template).
    ### Общепринятая нотация
    - $Х,x$ - Вектор входных данных, подаваемый в модель
    - $х=[х_1,\cdots,x_m]$ - Элементы одной записи, фичи (например пол, возраст и т.п) 
    - $m$ - Размерность данных, ко-во фич
    - $Y, y$ - Вектор ожидаемого результата (при обучении с учителем)
    - $\hat Y, \hat y, y'$ - Результат полученный на выходе в действительности
    - $Е=||y-\hat y||$ - Error, Loss, функция потерь, ошибка предсказания
    - $W,w$ - Веса (Weight) мат-модели
    - $w_0$ или $b$ - bias, смещение
    - $\sigma$ - Сигма, функция активации
    - $N$ - Kо-во элементов во входном датасете

