section
  h3 Введение
  ul
    li.fragment Нейронные сети это тип машинного обучения
    li.fragment Идея взята из устройства живого мозга
    li.fragment NN тяжелее обучать но по сравнению с другими алгоритмами ML, они часто дают более точные результаты
    li.fragment NN работают медленнее других алгоритмов ML
    li.fragment Существует масса различных архитекур NN
    li.fragment Самые популярные архитектуры Сверточные, Состязательные и Рекуррентные

section
  h2 Основы

section
  h3 Нейронная сеть
  img(src='img/nn_black_box.png')
  ul
    li.fragment Нейронная сеть это некий "черный ящик", мат-модель, имеющая вход и выход
    li.fragment Внутренне состоянии модели описывается параметрами $W$
    li.fragment На вход модели подаются данные $X$
    li.fragment На выходе получаем ответ $Y$

// section.
//   Задача обучения нейронной сети, заключается в поиске таких значений параметров модели $W$,
//   при котороых результат $Y$, будет иметь минимальную ошибку.
    
// section(data-markdown): textarea(data-template).
//   ### Сокращения
//   - ML - Machine Learning / машинное обучение
//   - NN - Artificial Neural Network / искуственные нейронные сети
//   - DL - Deep Learning / обучение глубоких нейронных сетей

  
section
  h3 Основные термины
  ul
    li.fragment: <a>neuron             </a> - нейрон (искуственный)
    li.fragment: <a>activation function</a> - функция активации
    li.fragment: <a>error (loss)       </a> - ошибка / функция потерь
    li.fragment: <a>gradientdescent    </a> - градиентный спуск
    li.fragment: <a>backpropagation    </a> - обратное распространение
    li.fragment: <a>overfit            </a> - переобучениe            

section
  h3 Стандартные обозначения
  ul
    li.fragment <a>$X$</a>      - входные данные подаваемый в модель
    li.fragment <a>$Y$</a>      - ожидаемый результат
    li.fragment <a>$\hat Y$</a> - полученный результат
    li.fragment <a>$E$</a>      - ошибка предсказания
    li.fragment <a>$W$</a>      - параметры модели

  
section
  h3 Совсем Немного математики
  img.plain.small(src="img/pushen_aaa.png")

    
section
  h3 линейнoe уравнение
  
  p.fragment $y = w_0 + w_1 x_1$
  p.fragment $y = w_0 + w_1 x_1 + w_2 x_2$
  p.fragment $\cdots$
  p.fragment $y= w_0 + w_1 х_1 + w_2 х_2 + \cdots + w_n x_n$


section
  h3 вектор
  p.fragment $$\vec{w}=[w_0,w_1,\cdots, w_n] $$
  p.fragment $$\vec{x}=[x_0,x_1,\cdots, x_n] $$
  p.fragment
    | Произведение векторов (скалярное)
    | $$\vec{w}\cdot\vec{x}=w_0 x_0 + w_1 x_1 + \cdots + w_n x_n$$

section
  h3 матрица
  p.
    $$ W_{n \times m} =
    \begin{bmatrix}
      w_{0,0} & w_{0,1} & \cdots & w_{0,m} \\
      w_{1,0} & w_{1,1} & \cdots & w_{1,m} \\
      \cdots  & \cdots  & \cdots & \cdots  \\
      w_{n,0} & w_{n,1} & \cdots & w_{n,m}
    \end{bmatrix}$$
  small Матрицы обычно обозначаются заглавными буквами $X$, a их элементы строчными $x_{i,j}$

section
  h3 матрицы можно умножать
  p $A \cdot B = C$
  small: ul
    li ширина матрицы $A$ должна быть равна высоте матрицы $B$
    li результатом умножения будет новая матрица

  
section
  h3 Геометрический смысл
  img(src='img/dot_product.png')


section
  h3 Математический смысл
  p.
    $$
      W_{1 \times n} = [[w_0, w_1, \cdots, w_n]] \\
      X_{1 \times n} = [[x_0, x_1, \cdots, x_n]] \\
      W \cdot X^T = [[w_0 x_0 + w_1 x_1 + \cdots + w_n x_n]]_{1 \times 1}
    $$
      
section
  h2 ВЫДЫХАЕМ
  h6 этого вполне достаточно чтобы разобраться с нейронными сетями
  img.plain.small(src="img/pushen_godfather.png")
// section
//   h4 функция
//   p $f$ - математическое действие над аргументом
    
//
  section(data-markdown): textarea(data-template).
    ### Общепринятые сокращения

    - ML - Machine Learning / машинное обучение
    - NN, ANN - Artificial Neural Network / искуственные нейронные сети
    - DL - Deep Learning / обучение глубоких нейронных сетей
    - CNN - Convolution Neural Net / сверточные нейронные сети
    - RNN - Recurrent Neural Net / рекурентные нейронные сети
    - GAN - Generativ Adversarial Net / генеративно конкурентные сети
    - TF - TensorFlow
// 
  section(data-markdown): textarea(data-template).
    ### Общепринятая нотация
    - $Х,x$ - Вектор входных данных, подаваемый в модель
    - $х=[х_1,\cdots,x_m]$ - Элементы одной записи, фичи (например пол, возраст и т.п) 
    - $m$ - Размерность данных, ко-во фич
    - $Y, y$ - Вектор ожидаемого результата (при обучении с учителем)
    - $\hat Y, \hat y, y'$ - Результат полученный на выходе в действительности
    - $Е=||y-\hat y||$ - Error, Loss, функция потерь, ошибка предсказания
    - $W,w$ - Веса (Weight) мат-модели
    - $w_0$ или $b$ - bias, смещение
    - $\sigma$ - Сигма, функция активации
    - $N$ - Kо-во элементов во входном датасете

